{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\".\\database.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqliteDBReader(object):\n",
    "    \"\"\"\n",
    "    Provide streaming access to sqlite database records\n",
    "    \"\"\"\n",
    "    def __init__ (self,path):\n",
    "        self._cur=sqlite3.connect(path).cursor()\n",
    "        \n",
    "    def score_artist_album_reviews(self):\n",
    "        \"\"\"\n",
    "        Reads the database and returns a DF with  score,artist name,artist album,review  as columns\n",
    "        \"\"\"\n",
    "        \n",
    "        sql = \" SELECT R.score , A.artist , L.label , C.content FROM REVIEWS as R \\\n",
    "                JOIN ARTISTS as A on R.reviewid=A.reviewid \\\n",
    "                JOIN LABELS as L on R.reviewid=L.reviewid \\\n",
    "                JOIN CONTENT as C on R.reviewid=C.reviewid \\\n",
    "              \" \n",
    "        \n",
    "        #self._cur.execute(sql)\n",
    "        \n",
    "        #df = pd.read_sql_query(sql,sqlite3.connect(path))\n",
    "        #return df\n",
    "        #for score,band,album,text in iter(self._cur.fetchone, None):\n",
    "            #yield (score,band,album,text)\n",
    "        data=[]\n",
    "        for score,band,album,text in self._cur.execute(sql):\n",
    "             data.append((score,band,album,text))\n",
    "                \n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessor(object):\n",
    "    \"\"\"\n",
    "    The preprocessor wrap the SqliteDBReader and does tokenization and part of speech tagging\n",
    "    \"\"\"\n",
    "    def __init__(self,corpus):\n",
    "        \"\"\"\n",
    "        the corpus is the SqliteDBReader to preprocess\n",
    "        \"\"\"\n",
    "        self.corpus=corpus\n",
    "        #self.reviews=[]\n",
    "        #self.scores= []        \n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        segment a text into sentences, tokenize and tag the words in the corpus. Returns a list of sentences , which are lists\n",
    "        tagged words\n",
    "        \"\"\"\n",
    "        return [ \n",
    "            nltk.pos_tag(nltk.word_tokenize(sent))   \n",
    "            for sent in nltk.sent_tokenize(text)\n",
    "        ]\n",
    "        \n",
    "    def get_reviews(self):\n",
    "        reviews=[]\n",
    "        for (score,band,album,text) in self.corpus:\n",
    "            reviews.append(self.tokenize(text))\n",
    "            \n",
    "        return reviews\n",
    "\n",
    "    def get_scores(self):\n",
    "        \"\"\"\n",
    "        bin the scores into 4 groups\n",
    "        bad  : 0/0 < y < 3.0\n",
    "        okay : 3.0 < y < 5.0\n",
    "        good : 5.0 < y < 7.0\n",
    "        great: 7.0 < y < 10.0\n",
    "        \"\"\"\n",
    "        scores=[]\n",
    "        for (score,band,album,text) in self.corpus:\n",
    "            scores.append(score)\n",
    "            \n",
    "        return list(np.digitize(scores, [0.0,3.0,5.0,7.0,10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "    TextNormalizer will fitler stopwords,punctuation and do feature reduction with lemmatization\n",
    "    \"\"\"\n",
    "    def __init__ (self, language=\"english\"):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords=set(nltk.corpus.stopwords.words(language))\n",
    "    \n",
    "        \n",
    "    def is_stopword(self, token):\n",
    "        return token.lower() in self.stopwords\n",
    "        \n",
    "    def is_punct(self, token):\n",
    "        return all(\n",
    "            unicodedata.category(char).startswith('P') for char in token\n",
    "        )\n",
    "    \n",
    "    def lemmatize(self,token,pos_tag):\n",
    "        \n",
    "        tag = {\n",
    "            \"N\" : wn.NOUN,\n",
    "            \"V\" : wn.VERB,\n",
    "            \"R\" : wn.ADV,\n",
    "            \"J\" : wn.ADJ\n",
    "        }.get(pos_tag[0],wn.NOUN)\n",
    "        \n",
    "        return self.lemmatizer.lemmatize(token,tag)\n",
    "    \n",
    "    def normalize(self,documents):\n",
    "        return [\n",
    "            self.lemmatize(token,tag) \n",
    "            for sent in documents \n",
    "            for token,tag in sent \n",
    "            if not self.is_stopword(token) \n",
    "            and not self.is_punct(token)\n",
    "        ]\n",
    "        \n",
    "    def fit(self,documents,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,documents):\n",
    "        return [\" \".join(self.normalize(doc)) for doc in documents]\n",
    "        #return [\" \".join(self.normalize(doc)) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=SqliteDBReader(path).score_artist_album_reviews()\n",
    "y=preprocessor(corpus).get_scores()\n",
    "X=preprocessor(corpus).get_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline= Pipeline([\n",
    "    (\"Normalize\",TextNormalizer()),\n",
    "    (\"Vectorizer\",TfidfVectorizer()),\n",
    "    (\"Model\",MultinomialNB())\n",
    "])\n",
    "\n",
    "score=cross_val_score(pipeline,X,y,cv=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d2d780e36333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
